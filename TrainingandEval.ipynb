{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["AdP5KjvxxHzr","jkAFsA11v5da"],"authorship_tag":"ABX9TyPj09HsEClgTqeiBD76cEU0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## initial checks"],"metadata":{"id":"AdP5KjvxxHzr"}},{"cell_type":"markdown","source":["Check that we are using a CPU"],"metadata":{"id":"nLCO4sLWsfej"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"RBl8R6ie-rVP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702171703843,"user_tz":-60,"elapsed":5,"user":{"displayName":"karl simu","userId":"07697941644195271416"}},"outputId":"423662af-8d15-4420-a731-85dbc2659985"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Dec 10 01:28:23 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0    22W / 300W |      0MiB / 16384MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"markdown","source":["Install dependencies"],"metadata":{"id":"WuFhvj5VslQZ"}},{"cell_type":"code","source":["!add-apt-repository -y ppa:jonathonf/ffmpeg-4\n","!apt update\n","!apt install -y ffmpeg"],"metadata":{"id":"UPV7ES12BV51"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install datasets>=2.6.1\n","!pip install git+https://github.com/huggingface/transformers\n","!pip install librosa\n","!pip install evaluate>=0.30\n","!pip install jiwer\n","!pip install gradio\n","!pip install hopsworks"],"metadata":{"id":"ODB49jEsBxDo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Log in to huggingface hub with read premission"],"metadata":{"id":"MyiAFkCUrYCN"}},{"cell_type":"code","source":["from huggingface_hub import notebook_login\n","\n","notebook_login()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["341704eadac74f3fbe20d5adc295d59b","954f60a9cfbc46f3bed883e8c6c0ed4f","80d675ab06cf400ebeee268d7995375d","bed2a6cb6ce14917be3546206926120c","c4d678cce7fa4a18af064d6d70be4e31","d8b4794650d84d1fb5bad7236535da7f","67d66a3074364473a99fe932f5ef2e6b","fd8d0ace57664dc7ac203366f622829c","47d61835bb2a4447b12bee8acdb99eb7","ca91871b662c4c65b2af8d4db2b8a238","9bb460932bba4c5ca0b57d2cfd0bf7ce","0be473e48f544bb5a655c85ed389a2c5","98458c452e1e4499953a089eca3e107c","539a84d2f4d744bfa4e103c85ed311ed","9e3641c675ce4f4da9f4055002c84ad2","8b7f0564f6df4342a442bc511e409342","09d7b9c3cd4f401e9afa5d89f9bd44cd","07525dcc921b400f9dd7e806dbc6bac9","7838234dfa87498795b65472e4958d1f","7284d0a99fbb42988dc220ea6fdb8b8a","7996ba215938436f9f50e4b22c8e6740","9c2a77434c0f4bb28b134362bdac3929","e377f5415692427c8950578ea8c45410","e92d75791baa4a6e956be214c771783e","10212c258b7c4a83bc433e39fcb0958a","da151386f13243cf84d771c7f6dee7f1","2429a62e5a38433bab512f9db584399b","b8f1662c979c45e785e5190a4741b948","d19322b9fa5f486facd60417da25c839","b2521ac5ac24482087c43c4601acb6cb","42589d88c47b4154b23fe9855664952e","e7ca5b34174f4876974424ad170d44b8"]},"id":"y52Zu9zjEI6l","executionInfo":{"status":"ok","timestamp":1702148143751,"user_tz":-60,"elapsed":886,"user":{"displayName":"karl simu","userId":"07697941644195271416"}},"outputId":"090cedde-731f-4287-df4f-a61f9dc5e6d0"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"341704eadac74f3fbe20d5adc295d59b"}},"metadata":{}}]},{"cell_type":"markdown","source":["## Training & Eval\n"],"metadata":{"id":"jkAFsA11v5da"}},{"cell_type":"code","source":["!pip install datasets>=2.6.1\n","!pip install git+https://github.com/huggingface/transformers\n","!pip install librosa\n","!pip install evaluate>=0.30\n","!pip install jiwer\n","!pip install gradio\n","!pip install hopsworks\n","!pip install evaluate\n","!pip install accelerate -U\n","# session sometimes needs to be restarted?"],"metadata":{"id":"Ng8aNlUEz2BB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702163289766,"user_tz":-60,"elapsed":11930,"user":{"displayName":"karl simu","userId":"07697941644195271416"}},"outputId":"57f0c79e-8644-4a85-eb84-3f65137742d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.1)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.15.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.23.5)\n","Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.15)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.19.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.2)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (14.0.1)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.13.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.8.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2023.11.17)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.3.post1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n","Collecting accelerate\n","  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.8.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.0.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.0.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Installing collected packages: accelerate\n","Successfully installed accelerate-0.25.0\n"]}]},{"cell_type":"code","source":["import torch\n","\n","from dataclasses import dataclass\n","from typing import Any, Dict, List, Union\n","\n","@dataclass\n","class DataCollatorSpeechSeq2SeqWithPadding:\n","    processor: Any\n","\n","    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n","        # split inputs and labels since they have to be of different lengths and need different padding methods\n","        # first treat the audio inputs by simply returning torch tensors\n","        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n","        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n","\n","        # get the tokenized label sequences\n","        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n","        # pad the labels to max length\n","        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n","\n","        # replace padding with -100 to ignore loss correctly\n","        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n","\n","        # if bos token is appended in previous tokenization step,\n","        # cut bos token here as it's append later anyways\n","        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n","            labels = labels[:, 1:]\n","\n","        batch[\"labels\"] = labels\n","\n","        return batch"],"metadata":{"id":"0UwSeJlDtTc7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import WhisperFeatureExtractor\n","from transformers import WhisperTokenizer\n","\n","feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")\n","tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"Swedish\", task=\"transcribe\")"],"metadata":{"id":"ckUOP8zIq3nR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import WhisperProcessor\n","\n","processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"Swedish\", task=\"transcribe\")"],"metadata":{"id":"XmNNO8P4xiLa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"],"metadata":{"id":"fxEXZA-7vnKq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import evaluate\n","\n","metric = evaluate.load(\"wer\")"],"metadata":{"id":"R22z4LpSyJTj","executionInfo":{"status":"ok","timestamp":1702068400783,"user_tz":-60,"elapsed":6200,"user":{"displayName":"karl simu","userId":"07697941644195271416"}},"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["2fc160d4b6eb4b90ae3206f999e23e5f","257eb9bee042423f9ba3081a198ec524","e7a3e03d793c4ff2bf79106c758c158c","034018710b104036910d231a162058c0","38ecef5bbe9e436d93df9fe3f834906a","b83262ab87154d5ca60e62590d55c9f6","c3a838b18cea434aa4a2752cc3dff7d4","53f8768143b44caa98cb2a008421ce80","9d4c1bf384c344f798ee8e14bcfdfad3","1a557712daed46be976752ffae25dc3c","7f18cd446bf24133bbfde107075ff5a0"]},"outputId":"39f338d7-58ad-4001-a13d-36fa0ac0dcf5"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/4.49k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fc160d4b6eb4b90ae3206f999e23e5f"}},"metadata":{}}]},{"cell_type":"code","source":["def compute_metrics(pred):\n","    pred_ids = pred.predictions\n","    label_ids = pred.label_ids\n","\n","    # replace -100 with the pad_token_id\n","    label_ids[label_ids == -100] = tokenizer.pad_token_id\n","\n","    # we do not want to group tokens when computing the metrics\n","    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n","    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n","\n","    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n","\n","    return {\"wer\": wer}"],"metadata":{"id":"TZLmREmL1O4Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import WhisperForConditionalGeneration\n","\n","model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")"],"metadata":{"id":"GekQlrGO8ldO","executionInfo":{"status":"ok","timestamp":1702068416342,"user_tz":-60,"elapsed":8664,"user":{"displayName":"karl simu","userId":"07697941644195271416"}},"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["ff3050bd5a174477bb4ec52165b844f9","81387d33484142c986c13ae3203cef9c","6eb6cbc6680c495abf2669460f7feaf5","baa93c9d430c43599194f47df6b17e23","fbc8ff9dc9534c939701c6050b88531d","742a65a024ac4c01bd54bde0c90f51c4","d2b85c802f474f5bb4e2dac44b0bbc01","cb47f8377218451cb7b12f5f47286807","e43d02bfaf9e4cf7a717a06a46537153","372a6060eb2243a7a75e60866a8074d4","c5f3053bec924d2a94ffef0bc8066bab","4c0dc7352e3c4dbfb0308a84594468a8","fce086093fe34e40b2d1452710f2e220","474f58c1f4e74aaa90a49a815cc3fbca","ab3e71c89e3040b19c968616c643929e","afc8c2fac5ca4f529c09b258f346d379","bfa7a7f51cb4433a8bc484f8ec76e405","9bb32856497144b0bc40d7b7cf7ed3a9","a4386db724084db9b2e0da33920c2995","28be163dfb0a4c468b8af02f1088595a","8a80c711e6d0405f95417b68fbd32cc8","fe399e0bda7c4388b653ca5a58d0bc47","b3e2494129fe46cfbd6475417d92c7e3","7eaae7b9394b46d39095dfc6e5b660e8","1a7459cfd2444e2ab64cb3ecee621651","a8dfcf75c50d4afa9299098ead77fae3","684aa38a52654533acf21d365b18995a","ce18ec58b557413ab2d91fe630fcaa04","6fe62d4e34a24e23a9441b6a4905ffd7","a17cfcbd1ede47479e8dcfe90afdb041","a3638b7198db49848a68baf25b97daae","6721f6648a364bc9860c71a538d60936","2d1b590a051a4eea82a363a5e532fc0e"]},"outputId":"f8b3f025-d1ef-49b1-b5b6-f5d83f6d1d1f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/1.97k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff3050bd5a174477bb4ec52165b844f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c0dc7352e3c4dbfb0308a84594468a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/3.84k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3e2494129fe46cfbd6475417d92c7e3"}},"metadata":{}}]},{"cell_type":"code","source":["model.config.forced_decoder_ids = None\n","model.config.suppress_tokens = []"],"metadata":{"id":"cMUkgaKV850C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Mount drive"],"metadata":{"id":"a2cKgQ6JvDSf"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1xDLkhhj9HFv","executionInfo":{"status":"ok","timestamp":1702068445074,"user_tz":-60,"elapsed":21199,"user":{"displayName":"karl simu","userId":"07697941644195271416"}},"outputId":"d5f83897-88e9-40cc-e98d-4f7d71bcfcd5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["Specify trainer arguments"],"metadata":{"id":"AMsFIWfHvE-B"}},{"cell_type":"code","source":["from transformers import Seq2SeqTrainingArguments\n","\n","training_args = Seq2SeqTrainingArguments(\n","    num_train_epochs=1,\n","    output_dir=\"/content/drive/MyDrive/ID2223/swedish_m_2\",  # change to a repo name of your choice\n","    per_device_train_batch_size=8,\n","    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n","    learning_rate=1e-5,\n","    warmup_steps=250,\n","    max_steps=2000,\n","    gradient_checkpointing=True,\n","    fp16=True,\n","    evaluation_strategy=\"steps\",\n","    per_device_eval_batch_size=8,\n","    predict_with_generate=True,\n","    generation_max_length=225,\n","    save_steps=250,\n","    eval_steps=250,\n","    logging_steps=25,\n","    report_to=[\"tensorboard\"],\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"wer\",\n","    greater_is_better=False,\n","    push_to_hub=True,\n",")"],"metadata":{"id":"HfWUVnBi4QFR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","from transformers import Seq2SeqTrainingArguments\n","\n","training_args = Seq2SeqTrainingArguments(\n","    num_train_epochs=1,\n","    output_dir=\"/content/drive/MyDrive/ID2223/swedish_training\",  # change to a repo name of your choice\n","    per_device_train_batch_size=16,\n","    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n","    learning_rate=1e-5,\n","    warmup_steps=500,\n","    max_steps=4000,\n","    gradient_checkpointing=True,\n","    fp16=True,\n","    evaluation_strategy=\"no\",\n","    per_device_eval_batch_size=8,\n","    predict_with_generate=True,\n","    generation_max_length=225,\n","    save_steps=1,\n","    eval_steps=1,\n","    logging_steps=25,\n","    report_to=[\"tensorboard\"],\n","    load_best_model_at_end=False,\n","    metric_for_best_model=\"wer\",\n","    greater_is_better=False,\n","    push_to_hub=True,\n",")\n","\"\"\""],"metadata":{"id":"7KMellCy9BPh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Load dataset"],"metadata":{"id":"ljm0Q0FeuOkN"}},{"cell_type":"code","source":["from datasets import load_from_disk\n","common_voice_reloaded = load_from_disk('/content/drive/MyDrive/ID2223/common_voice')\n","common_voice_reloaded"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zRarw_Hn_YB5","executionInfo":{"status":"ok","timestamp":1702068528390,"user_tz":-60,"elapsed":68369,"user":{"displayName":"karl simu","userId":"07697941644195271416"}},"outputId":"2697809e-9c61-4899-ce7d-45c12e007b66"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['input_features', 'labels'],\n","        num_rows: 12360\n","    })\n","    test: Dataset({\n","        features: ['input_features', 'labels'],\n","        num_rows: 5069\n","    })\n","})"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["log in with write premission"],"metadata":{"id":"bT0kIO4Brc2E"}},{"cell_type":"code","source":["from huggingface_hub import notebook_login\n","\n","notebook_login()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["3e3a9cc5d6004da686cc415aa657a2c3","d6400c15480d41a58029d83770674df2","8dd597501d0d46b6ab18ed2ef1a5602b","e49aadc8d9184088b9649dbff13c373e","09edfe6a4e434f6f9bb9acf4bfacf94e","d4a6579ccf224d9b96bdae64f17f51e5","18f32f5238ce456d9ab84145fe32b76e","444b5a09f5b14c6196afd87bf58a606d","9c42a33a53c64749bd52bef1563ae102","3925f3879de049afb1d430ce5009a16c","3e58a9be29284fde94a79cd8d3a6786d","a5beefdcf15b4a76bd0e674f6a1a2ec7","4c124ee2ba364a34b361d95be2413956","ffc88ed40c94409b89c19ebe8e35573b","ef0a2d4d4f9e4872b0568a43b41b570a","2266a2a892914368ac619c80a7c8fc24","3b95fbef3578450fb62a2ba9dda890e9","76a3b5c890b546cd8bc1e4976fd4335a","16379e70b2f942489a892f64975a02d3","3f36b2ecccd040ec917fc9c31dfb74fe","909955e03e9346fc82d9ee5f908f9c9d","a0da822074f340c6be7a4db63d42536c","2f47240446e24b77bd012d4d4aab0b7a","c8a64276ac6141ed9096b2283811e559","2f3fd1c43246491789543c08802ad1f7","6c2aa4b53e2c4356abb77653060b8270","d58e15266e5a47c7b867378a26809ecf","a3d431dd5121484a96ef65f24ac0716e","43b58a1f17044e6cb1036434f78fb9f5","78d4f75110414577ad6a065db64f2389","267a29d12bf24411b0fe4e150bf27f91","76a2ecb270484e8a9fc795b3a121bbe6"]},"id":"XwTy27iCD_nJ","executionInfo":{"status":"ok","timestamp":1702068533436,"user_tz":-60,"elapsed":9,"user":{"displayName":"karl simu","userId":"07697941644195271416"}},"outputId":"38dca643-57f6-42df-f47e-d969008d3cc8"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e3a9cc5d6004da686cc415aa657a2c3"}},"metadata":{}}]},{"cell_type":"markdown","source":["put it all in the trainer"],"metadata":{"id":"S4_-e4qzvJqA"}},{"cell_type":"code","source":["from transformers import Seq2SeqTrainer\n","\n","trainer = Seq2SeqTrainer(\n","    args=training_args,\n","    model=model,\n","    train_dataset=common_voice_reloaded[\"train\"],\n","    eval_dataset=common_voice_reloaded[\"test\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n","    tokenizer=processor.feature_extractor,\n",")"],"metadata":{"id":"YUtRknpzBSxn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["save the processor (as the processor is static/ wont change with training)"],"metadata":{"id":"HfISL3pCvMEL"}},{"cell_type":"code","source":["processor.save_pretrained(training_args.output_dir)"],"metadata":{"id":"umxh3as4EI71"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["paste to browser console \\n\n","another tip is https://nosleep.page/\n","\n","---\n","\n"],"metadata":{"id":"5-qhbB84r32Y"}},{"cell_type":"code","source":["\"\"\"\n","function ConnectButton(){\n","    console.log(\"Connect pushed\");\n","    document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click()\n","}\n","setInterval(ConnectButton, 60000);\n","\"\"\""],"metadata":{"id":"fE3c5dXmEeam"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Only do below this first time use next section/notebook otherwise"],"metadata":{"id":"rlwnxmL4rpOP"}},{"cell_type":"code","source":["trainer.train()"],"metadata":{"id":"KEQaZfWSFfji","colab":{"base_uri":"https://localhost:8080/","height":283},"outputId":"06dbb7d3-ef4b-42ee-93f7-2cf1ab8843f1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='719' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 719/3000 2:58:22 < 9:27:27, 0.07 it/s, Epoch 0.46/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Wer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>250</td>\n","      <td>0.350300</td>\n","      <td>0.375748</td>\n","      <td>33.284935</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.344800</td>\n","      <td>0.346996</td>\n","      <td>45.435724</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n"]}]}]}