{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["AdP5KjvxxHzr","-kE4ujBQJKb9"],"authorship_tag":"ABX9TyMgiuPLoZDUFiW/IDvZX82k"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## initial checks"],"metadata":{"id":"AdP5KjvxxHzr"}},{"cell_type":"markdown","source":["Check that we are using a CPU"],"metadata":{"id":"nLCO4sLWsfej"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"RBl8R6ie-rVP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702171703843,"user_tz":-60,"elapsed":5,"user":{"displayName":"karl simu","userId":"07697941644195271416"}},"outputId":"423662af-8d15-4420-a731-85dbc2659985"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Dec 10 01:28:23 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0    22W / 300W |      0MiB / 16384MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"markdown","source":["Install dependencies"],"metadata":{"id":"WuFhvj5VslQZ"}},{"cell_type":"code","source":["!add-apt-repository -y ppa:jonathonf/ffmpeg-4\n","!apt update\n","!apt install -y ffmpeg"],"metadata":{"id":"UPV7ES12BV51"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install datasets>=2.6.1\n","!pip install git+https://github.com/huggingface/transformers\n","!pip install librosa\n","!pip install evaluate>=0.30\n","!pip install jiwer\n","!pip install gradio\n","!pip install hopsworks"],"metadata":{"id":"ODB49jEsBxDo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Log in to huggingface hub with read premission"],"metadata":{"id":"MyiAFkCUrYCN"}},{"cell_type":"code","source":["from huggingface_hub import notebook_login\n","\n","notebook_login()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["341704eadac74f3fbe20d5adc295d59b","954f60a9cfbc46f3bed883e8c6c0ed4f","80d675ab06cf400ebeee268d7995375d","bed2a6cb6ce14917be3546206926120c","c4d678cce7fa4a18af064d6d70be4e31","d8b4794650d84d1fb5bad7236535da7f","67d66a3074364473a99fe932f5ef2e6b","fd8d0ace57664dc7ac203366f622829c","47d61835bb2a4447b12bee8acdb99eb7","ca91871b662c4c65b2af8d4db2b8a238","9bb460932bba4c5ca0b57d2cfd0bf7ce","0be473e48f544bb5a655c85ed389a2c5","98458c452e1e4499953a089eca3e107c","539a84d2f4d744bfa4e103c85ed311ed","9e3641c675ce4f4da9f4055002c84ad2","8b7f0564f6df4342a442bc511e409342","09d7b9c3cd4f401e9afa5d89f9bd44cd","07525dcc921b400f9dd7e806dbc6bac9","7838234dfa87498795b65472e4958d1f","7284d0a99fbb42988dc220ea6fdb8b8a","7996ba215938436f9f50e4b22c8e6740","9c2a77434c0f4bb28b134362bdac3929","e377f5415692427c8950578ea8c45410","e92d75791baa4a6e956be214c771783e","10212c258b7c4a83bc433e39fcb0958a","da151386f13243cf84d771c7f6dee7f1","2429a62e5a38433bab512f9db584399b","b8f1662c979c45e785e5190a4741b948","d19322b9fa5f486facd60417da25c839","b2521ac5ac24482087c43c4601acb6cb","42589d88c47b4154b23fe9855664952e","e7ca5b34174f4876974424ad170d44b8"]},"id":"y52Zu9zjEI6l","executionInfo":{"status":"ok","timestamp":1702148143751,"user_tz":-60,"elapsed":886,"user":{"displayName":"karl simu","userId":"07697941644195271416"}},"outputId":"090cedde-731f-4287-df4f-a61f9dc5e6d0"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"341704eadac74f3fbe20d5adc295d59b"}},"metadata":{}}]},{"cell_type":"markdown","source":["## Resuming training"],"metadata":{"id":"-kE4ujBQJKb9"}},{"cell_type":"code","source":["!pip install datasets>=2.6.1\n","!pip install git+https://github.com/huggingface/transformers\n","!pip install librosa\n","!pip install evaluate>=0.30\n","!pip install jiwer\n","!pip install gradio\n","!pip install hopsworks\n","!pip install evaluate\n","!pip install accelerate -U\n","# session sometimes needs to be restarted? if you are starting from checkpoint"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dcfTU-hlAZqs","executionInfo":{"status":"ok","timestamp":1702171684316,"user_tz":-60,"elapsed":11893,"user":{"displayName":"karl simu","userId":"07697941644195271416"}},"outputId":"00a4ecb5-235f-4116-b8ea-3ea614461e48"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.1)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.15.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.23.5)\n","Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.15)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.19.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.2)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (14.0.1)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.13.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2023.11.17)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.3.post1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n","Collecting accelerate\n","  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.9.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.0.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.0.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Installing collected packages: accelerate\n","Successfully installed accelerate-0.25.0\n"]}]},{"cell_type":"markdown","source":["Imports"],"metadata":{"id":"tLlT70odvt3I"}},{"cell_type":"code","source":["import torch\n","from dataclasses import dataclass\n","from typing import Any, Dict, List, Union\n","from transformers import WhisperFeatureExtractor\n","from transformers import WhisperTokenizer\n","from transformers import WhisperProcessor\n","import evaluate\n","from transformers import WhisperForConditionalGeneration\n","from transformers import Seq2SeqTrainingArguments\n","from datasets import load_from_disk\n","from transformers import Seq2SeqTrainer"],"metadata":{"id":"mDmNs8LELRws"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["log in with read and write premission"],"metadata":{"id":"NEKIWEPqKfHc"}},{"cell_type":"code","source":["from huggingface_hub import notebook_login\n","\n","notebook_login()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["00c9e9badd7f429086b70a3a780eaa9f","c1ed6acd53ff43deb594a9f8f61e6f1a","757822258c7b408b822cb4a9492de690","8bbcfa833eb049f691552fb8be34156c","ad9baa7098994d1dbd05a6e204665377","51d72e1690de4bf2af1f78bec1d31984","6fd27228bc08485b8c1ff48ddd368584","55c48adcf33b44bebc67134fce6ced7d","a641f31dbb934303a005d064b1b74ebd","fc841ad3033145599a1fd0800ddbd52f","04c8e33b3af74b9baf2c97086aa8f573","cf09a83982a34aed9ab14d0a15218074","8f8ca196140240b0997a7d2b1679adc5","7822f2c65fd2410fa8c2679cc3058590","b9cb5aeff0fc4539ae6c2b7c9bad894b","35fdfe9f6c8f48ca99cae99cf55b95fb","4bfb4d0353a1444d9541d00194ed7705","a1a5cf5627154aaaa58f151915ab1cca","8212356d618b46e6ba3ad8198863cf49","8e353401b4cd4def9fe7e14571be71cc","80e3472941654d419943def3af4002bd","b67fd5dba8d24192b1fd17f5d94ad12d","28634cef95ae4e50a9eb1a396464747a","1d302b5c610f45319a7ec0111c518b4b","8aa1b2a00a6c4a8593f324fc4302d6e0","27008930fe6e4b4f897cf02251995eaa","d2e84a84868c4a97b613af44bb7167a4","ba346979dc6941bd9b3a56a75d69c8be","9f678fb2f21f414ba47d19ef1df9a883","fce1dbd8f8a847efa2ddce98fe543c8a","37eb7577b8a84aa08e19bd6b557c8bd9","a445812d43224763b7e165ded3815ce3"]},"executionInfo":{"status":"ok","timestamp":1702171724586,"user_tz":-60,"elapsed":325,"user":{"displayName":"karl simu","userId":"07697941644195271416"}},"outputId":"fb1f4891-b32c-4d92-ec1b-e00f781d944e","id":"utt0ZeXaKfHr"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00c9e9badd7f429086b70a3a780eaa9f"}},"metadata":{}}]},{"cell_type":"code","source":["notebook_login()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["50bd985cb1a74ca99942a0fef29ad521","7edb44546d9f45ee89693a4fa7b92ad0","cce854aaddf547a6b123ce8914eaf6a0","c9cc338f140e4371b05dc8bc609e0781","66ee8798b4aa4001970aafadc930fd72","e970c1e8d0334bc5b04e74c4e741f6f2","0cbc32ebaba64704a588c6cdce1dafc9","f0ccea4160a54c4f990e45abc3f34daf","f7126e451d604df98c783d31d95a8bdd","57b6d12e52a84357bad05847a6ec1b9a","e4f21a615d7d40658c126d3e7e29c6b1","41b54e9c6f804607be4774ace99bc7d1","a19ceecf09bb4e54954f397b6bb2eb17","0f86af222a10405684d38e1372ab5964","24173139350b4a498678f4c65df0f9d3","ac2127617661478f90e38f56f882a59b","1277541f8f604981ad315feab3e8c16f","a6e5bc0708c446418e5ae75dc6ad5ad1","e319c937551b4a12880c44fe0961f923","9a53a2a6e769474fb5f94c6c52297551","f5812f1954634848997d5499ca0dd5c3","f653436d59c5460a95e0512a3bdf4516","5868d6b4041a4bdf9ce200d2b3dcb852","481c370524c248b2a3324a6f75fe700a","706f97a28caa4e9ab2b94dbb6853d910","561efaa939be41a59bcaae90f17a25e6","c3b288cf708c4781a6908d7d7e7cde95","6af522f4a40c4f8591759f03ae9ff5d6","ee13f9c2cd4b4869b0892bf8b6469a59","4392d8d9cbd94461bfb49c4c2f155857","da0e5c607e9b4a988deefb474bc477e8","a5989c0271424afe95a8d70e22055426"]},"id":"VdXXkIS0B7Lb","executionInfo":{"status":"ok","timestamp":1702171734853,"user_tz":-60,"elapsed":546,"user":{"displayName":"karl simu","userId":"07697941644195271416"}},"outputId":"b78b7cad-baad-4a7b-ae4a-126d15d7e87c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50bd985cb1a74ca99942a0fef29ad521"}},"metadata":{}}]},{"cell_type":"markdown","source":["mount drive"],"metadata":{"id":"v1jBmjIOzY5_"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"efwReKEqKL1l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702171764173,"user_tz":-60,"elapsed":20038,"user":{"displayName":"karl simu","userId":"07697941644195271416"}},"outputId":"07b1cc80-0204-459e-de3d-1c6112cf135e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["change \"glob_checkpoint_url\" to the most recent model chechpoint.\n","glob_resume_url wont change unless you want to change model/repo"],"metadata":{"id":"1jXa1l5-v20J"}},{"cell_type":"code","source":["glob_resume_url = \"/content/drive/MyDrive/ID2223/swedish_m_2\"\n","glob_checkpoint_url = \"/content/drive/MyDrive/ID2223/swedish_m_2/checkpoint-1500\""],"metadata":{"id":"MfGQ4aBD-8ej"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Re-run some of the code (since the session timed out)"],"metadata":{"id":"ijxddFZiztqn"}},{"cell_type":"code","source":["@dataclass\n","class DataCollatorSpeechSeq2SeqWithPadding:\n","    processor: Any\n","\n","    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n","        # split inputs and labels since they have to be of different lengths and need different padding methods\n","        # first treat the audio inputs by simply returning torch tensors\n","        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n","        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n","\n","        # get the tokenized label sequences\n","        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n","        # pad the labels to max length\n","        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n","\n","        # replace padding with -100 to ignore loss correctly\n","        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n","\n","        # if bos token is appended in previous tokenization step,\n","        # cut bos token here as it's append later anyways\n","        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n","            labels = labels[:, 1:]\n","\n","        batch[\"labels\"] = labels\n","\n","        return batch"],"metadata":{"id":"7TVEDw3I0Nfk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Load the processor"],"metadata":{"id":"ZVZ5-8Kh5Qxo"}},{"cell_type":"code","source":["processor_url = glob_resume_url"],"metadata":{"id":"sOrNfIu249U-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["feature_extractor = WhisperFeatureExtractor.from_pretrained(processor_url)\n","tokenizer = WhisperTokenizer.from_pretrained(processor_url, language=\"Swedish\", task=\"transcribe\")\n","processor = WhisperProcessor.from_pretrained(processor_url, language=\"Swedish\", task=\"transcribe\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g5h4gFB24Yt9","executionInfo":{"status":"ok","timestamp":1702171797210,"user_tz":-60,"elapsed":2317,"user":{"displayName":"karl simu","userId":"07697941644195271416"}},"outputId":"61365a8d-98aa-46da-a2ff-75b15f5f7b02"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"markdown","source":["re-run some more"],"metadata":{"id":"QA0b7kyD5XNI"}},{"cell_type":"code","source":["data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n","\n","metric = evaluate.load(\"wer\")\n","\n","def compute_metrics(pred):\n","    pred_ids = pred.predictions\n","    label_ids = pred.label_ids\n","\n","    # replace -100 with the pad_token_id\n","    label_ids[label_ids == -100] = tokenizer.pad_token_id\n","\n","    # we do not want to group tokens when computing the metrics\n","    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n","    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n","\n","    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n","\n","    return {\"wer\": wer}"],"metadata":{"id":"9DDEAWam4bO6","executionInfo":{"status":"ok","timestamp":1702171803473,"user_tz":-60,"elapsed":2073,"user":{"displayName":"karl simu","userId":"07697941644195271416"}},"colab":{"base_uri":"https://localhost:8080/","height":77,"referenced_widgets":["7a17e2c83ea9462f8adc88cd51ed005a","0dd5f752b7ee42e9a855c604606e55ba","c7eb59f7c68c43e0bf7050429cf1ed29","5a3c7c421fc04941aa6d2e00d9af5208","7913443325944e90ab93797ada45d14e","4e452abfe63c42578cbc52f95e1c7683","650a2aa14a3e4d2197b857d4d512c8eb","71ed9c1ceff6472f927fc0a3981ba433","8ddf52246311438c982b555d3c2b2212","81f23e2fa58444e882da80034e62084f","2d7152814d9545639e86b57df4858694"]},"outputId":"b3771dbe-e309-4304-c038-26d939375323"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/4.49k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a17e2c83ea9462f8adc88cd51ed005a"}},"metadata":{}}]},{"cell_type":"markdown","source":["update to the most recent url"],"metadata":{"id":"iGsDoG0o1qY9"}},{"cell_type":"code","source":["checkpoint_model_url = glob_checkpoint_url"],"metadata":{"id":"WkEOprfP1lbl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["load the most recent model"],"metadata":{"id":"WpuHPZiU2ule"}},{"cell_type":"code","source":["model = WhisperForConditionalGeneration.from_pretrained(checkpoint_model_url)\n","model.config.forced_decoder_ids = None\n","model.config.suppress_tokens = []"],"metadata":{"id":"4cYHZmZ71WFl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Re-run some more code, load dataset"],"metadata":{"id":"iDgCT4sq3fZq"}},{"cell_type":"code","source":["training_args = Seq2SeqTrainingArguments(\n","    num_train_epochs=1,\n","    output_dir=\"/content/drive/MyDrive/ID2223/swedish_m_2\",  # change to a repo name of your choice\n","    per_device_train_batch_size=8,\n","    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n","    learning_rate=1e-5,\n","    warmup_steps=250,\n","    max_steps=2000,\n","    gradient_checkpointing=True,\n","    fp16=True,\n","    evaluation_strategy=\"steps\",\n","    per_device_eval_batch_size=8,\n","    predict_with_generate=True,\n","    generation_max_length=225,\n","    save_steps=250,\n","    eval_steps=250,\n","    logging_steps=25,\n","    report_to=[\"tensorboard\"],\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"wer\",\n","    greater_is_better=False,\n","    push_to_hub=True,\n",")\n","\n","common_voice_reloaded = load_from_disk('/content/drive/MyDrive/ID2223/common_voice')\n","\n","trainer = Seq2SeqTrainer(\n","    args=training_args,\n","    model=model,\n","    train_dataset=common_voice_reloaded[\"train\"],\n","    eval_dataset=common_voice_reloaded[\"test\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n","    tokenizer=processor.feature_extractor,\n",")"],"metadata":{"id":"xuEIExyD2fkD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["to see that we start from checkpoint"],"metadata":{"id":"nubDPWADDfKp"}},{"cell_type":"code","source":["import transformers\n","transformers.logging.set_verbosity_info()"],"metadata":{"id":"oCuhHMO0DiWD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Resume training"],"metadata":{"id":"_Tb6uhq86iGv"}},{"cell_type":"code","source":["checkpoint_trainer_url = glob_checkpoint_url"],"metadata":{"id":"GhEpcUQh3YDt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train(resume_from_checkpoint=checkpoint_trainer_url)\n"],"metadata":{"id":"XFaSXenXF3lR","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"1aa32ec9-da73-4712-b817-52e7f5a2b34a","executionInfo":{"status":"ok","timestamp":1702180386419,"user_tz":-60,"elapsed":8495459,"user":{"displayName":"karl simu","userId":"07697941644195271416"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Loading model from /content/drive/MyDrive/ID2223/swedish_m_2/checkpoint-1500.\n","There were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n","***** Running training *****\n","  Num examples = 12,360\n","  Num Epochs = 2\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2,000\n","  Number of trainable parameters = 240,582,912\n","  Continuing training from checkpoint, will skip to saved global_step\n","  Continuing training from epoch 0\n","  Continuing training from global step 1500\n","  Will skip the first 0 epochs then the first 1500 batches in the first epoch.\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2000/2000 2:20:25, Epoch 1/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Wer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.114000</td>\n","      <td>0.282170</td>\n","      <td>67.080745</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.108200</td>\n","      <td>0.278629</td>\n","      <td>74.343255</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 5069\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/MyDrive/ID2223/swedish_m_2/tmp-checkpoint-1750\n","Configuration saved in /content/drive/MyDrive/ID2223/swedish_m_2/tmp-checkpoint-1750/config.json\n","Configuration saved in /content/drive/MyDrive/ID2223/swedish_m_2/tmp-checkpoint-1750/generation_config.json\n","Model weights saved in /content/drive/MyDrive/ID2223/swedish_m_2/tmp-checkpoint-1750/pytorch_model.bin\n","Feature extractor saved in /content/drive/MyDrive/ID2223/swedish_m_2/tmp-checkpoint-1750/preprocessor_config.json\n","Feature extractor saved in /content/drive/MyDrive/ID2223/swedish_m_2/preprocessor_config.json\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","***** Running Evaluation *****\n","  Num examples = 5069\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/MyDrive/ID2223/swedish_m_2/tmp-checkpoint-2000\n","Configuration saved in /content/drive/MyDrive/ID2223/swedish_m_2/tmp-checkpoint-2000/config.json\n","Configuration saved in /content/drive/MyDrive/ID2223/swedish_m_2/tmp-checkpoint-2000/generation_config.json\n","Model weights saved in /content/drive/MyDrive/ID2223/swedish_m_2/tmp-checkpoint-2000/pytorch_model.bin\n","Feature extractor saved in /content/drive/MyDrive/ID2223/swedish_m_2/tmp-checkpoint-2000/preprocessor_config.json\n","Feature extractor saved in /content/drive/MyDrive/ID2223/swedish_m_2/preprocessor_config.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/ID2223/swedish_m_2/checkpoint-250 (score: 33.28493452717055).\n","There were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n","Waiting for the current checkpoint push to be finished, this might take a couple of minutes.\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=2000, training_loss=0.029645836114883424, metrics={'train_runtime': 8444.1157, 'train_samples_per_second': 1.895, 'train_steps_per_second': 0.237, 'total_flos': 4.61736640512e+18, 'train_loss': 0.029645836114883424, 'epoch': 1.29})"]},"metadata":{},"execution_count":16}]}]}